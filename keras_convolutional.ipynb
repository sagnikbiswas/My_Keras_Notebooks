{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_convolutional.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNppNH2Fte7P212Z16KG8VJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagnikbiswas/My_Keras_Notebooks/blob/main/keras_convolutional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Bj51yyem6A"
      },
      "source": [
        "#Building a Convolutional Neural Network with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coZsYL5Cg-jM"
      },
      "source": [
        "In this notebook we will be training a CNN with the MNIST dataset. MNIST is a handwritten digit image database.\n",
        "\n",
        "**Use GPU for training if you are using Colab. It is ~25 times faster than CPU.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzQkP_kBWD2r"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rC2KUVANrUC",
        "outputId": "d0b754a6-fc04-4783-ac36-f3fb45fb8fe1"
      },
      "source": [
        "# load MNIST data.\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-ibBzkROVwp"
      },
      "source": [
        "# Why reshape with a fourth dimension 1? Because Keras Conv2D expects 4D input, i.e. sample_size, height, width, channel_size\n",
        "# We have greyscale images in MNIST so the channel_size is 1\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqoPVS5POtcC"
      },
      "source": [
        "# Encode y values into one hot vectors\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# number of outputs in the model\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKAal7cNi2pt"
      },
      "source": [
        "###Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLpRnCiboA_T"
      },
      "source": [
        "####Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GjIxNFXi7Vb"
      },
      "source": [
        "A CNN has:\n",
        "    input layer,\n",
        "    one or more convolution + ReLU (Keras Conv2D) layers,\n",
        "    one or more corresponding max pool layers (Keras MaxPooling2D),\n",
        "    a flatten layer for flattening the output into a 1D vector,\n",
        "    one or more dense layers,\n",
        "    and an output softmax layer.\n",
        "\n",
        "In `keras_classification` we trained the same MNIST data using a conventional NN, but we had to use 784 input neurons corresponding to every feature (pixel*channel) of the image. For higher resolution image, it is impractical to use millions of input neurons, thus CNN enters the scene. In a CNN the Conv filters extract features (edges etc), the pooling layer reduces dimensionality and risk of overfitting, and the dense layers are identical to normal NNs.\n",
        "\n",
        "The following model has one Conv2D and one MaxPooling2D layer. Conv2D is taking input filters=16, kernel_size=(5,5), strides=(1,1) (default). MaxPooling2D has pool_size=(2,2) (default) and strides=(2,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWtminixoGqi"
      },
      "source": [
        "####Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A0rMw3rRdS3"
      },
      "source": [
        "def my_convolutional_model_1():\n",
        "    my_model = Sequential()\n",
        "    my_model.add(Conv2D(16, (5,5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    my_model.add(MaxPooling2D(strides=(2, 2)))\n",
        "\n",
        "    my_model.add(Flatten())\n",
        "    my_model.add(Dense(100, activation='relu'))\n",
        "    my_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return my_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KvPhS0vlk66"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqglLs2QUSdJ",
        "outputId": "9629f9f1-cdbd-42ab-f660-4732bb2a3dee"
      },
      "source": [
        "my_model_1 = my_convolutional_model_1()\n",
        "\n",
        "my_model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 44s - loss: 0.2829 - accuracy: 0.9216 - val_loss: 0.0909 - val_accuracy: 0.9733\n",
            "Epoch 2/10\n",
            "300/300 - 1s - loss: 0.0828 - accuracy: 0.9759 - val_loss: 0.0655 - val_accuracy: 0.9794\n",
            "Epoch 3/10\n",
            "300/300 - 1s - loss: 0.0574 - accuracy: 0.9825 - val_loss: 0.0507 - val_accuracy: 0.9831\n",
            "Epoch 4/10\n",
            "300/300 - 1s - loss: 0.0459 - accuracy: 0.9861 - val_loss: 0.0468 - val_accuracy: 0.9856\n",
            "Epoch 5/10\n",
            "300/300 - 1s - loss: 0.0374 - accuracy: 0.9888 - val_loss: 0.0410 - val_accuracy: 0.9856\n",
            "Epoch 6/10\n",
            "300/300 - 1s - loss: 0.0307 - accuracy: 0.9907 - val_loss: 0.0481 - val_accuracy: 0.9853\n",
            "Epoch 7/10\n",
            "300/300 - 1s - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.0354 - val_accuracy: 0.9886\n",
            "Epoch 8/10\n",
            "300/300 - 1s - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0379 - val_accuracy: 0.9875\n",
            "Epoch 9/10\n",
            "300/300 - 1s - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0375 - val_accuracy: 0.9876\n",
            "Epoch 10/10\n",
            "300/300 - 1s - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0363 - val_accuracy: 0.9894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce3a5b4750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP2SFbe8lp6P"
      },
      "source": [
        "###Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMpBy4LbYmYN",
        "outputId": "e8403f4d-5aed-4127-808d-7c16012ea913"
      },
      "source": [
        "scores = my_model_1.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Accuracy: {scores[1]*100}%\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.94000291824341%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfPtyvYvlr9R"
      },
      "source": [
        "###Building another model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-6rgzp2l73O"
      },
      "source": [
        "This model has two Conv2D and two MaxPooling2D layers. Generally we use less filters (16) in the earlier layer where the dimensions are bigger, and more filters (32) in the later layers with reduced dimension sizes. In this example, using more than two conv and pool layer did not improve accuracy. Using (1,1) stride for pooling resulted in more oscillatory accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu-4TbbuZKtM"
      },
      "source": [
        "def my_convolutional_model_2():\n",
        "    my_model = Sequential()\n",
        "    my_model.add(Conv2D(16, (5,5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    my_model.add(MaxPooling2D(strides=(1, 1)))\n",
        "\n",
        "    my_model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "    my_model.add(MaxPooling2D(strides=(1,1)))\n",
        "\n",
        "    my_model.add(Flatten())\n",
        "    my_model.add(Dense(100, activation='relu'))\n",
        "    my_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return my_model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2LWqquLZ1Ze",
        "outputId": "e4659a4e-ca96-4d0d-b3b7-d4c33e7614f4"
      },
      "source": [
        "my_model_2 = my_convolutional_model_2()\n",
        "\n",
        "my_model_2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, verbose=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 - 4s - loss: 0.1297 - accuracy: 0.9609 - val_loss: 0.0387 - val_accuracy: 0.9871\n",
            "Epoch 2/10\n",
            "938/938 - 3s - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.0316 - val_accuracy: 0.9882\n",
            "Epoch 3/10\n",
            "938/938 - 3s - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.0235 - val_accuracy: 0.9923\n",
            "Epoch 4/10\n",
            "938/938 - 3s - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0335 - val_accuracy: 0.9891\n",
            "Epoch 5/10\n",
            "938/938 - 3s - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.0359 - val_accuracy: 0.9887\n",
            "Epoch 6/10\n",
            "938/938 - 3s - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0479 - val_accuracy: 0.9866\n",
            "Epoch 7/10\n",
            "938/938 - 3s - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0348 - val_accuracy: 0.9910\n",
            "Epoch 8/10\n",
            "938/938 - 3s - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0331 - val_accuracy: 0.9911\n",
            "Epoch 9/10\n",
            "938/938 - 3s - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0287 - val_accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "938/938 - 3s - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0320 - val_accuracy: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2964c890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufyuqU0uaBAL",
        "outputId": "5d9f3031-9209-4b0c-a45b-f2b81d021718"
      },
      "source": [
        "scores2 = my_model_2.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Accuracy: {scores2[1]*100}%\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.18000102043152%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH_bqGbEnDon"
      },
      "source": [
        "The accuracies of both models are pretty close. Using lower batch size and smaller pooling stride improves accuracy. Any other slight improvement in the second model seems unreliable at best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw0NGBYcaWYD"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}